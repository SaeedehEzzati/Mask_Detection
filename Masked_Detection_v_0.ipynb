{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.ezati\\Anaconda3\\envs\\emty_table\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "frame_x = 1250 #1250\n",
    "frame_y = 750 #750\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\s.ezati/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-1-21 Python-3.10.9 torch-1.13.0+cu117 CUDA:0 (NVIDIA GeForce RTX 3060, 12287MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7018216 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "masked_model = torch.hub.load('ultralytics/yolov5', 'custom', path='mask_yolov5.pt',device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Masked_Detection(img,img_original,ROI_Region):\n",
    "    save_flag = False\n",
    "    resize_frame = None\n",
    "    now_time = datetime.now().strftime(\"%Y_%m_%d---%I_%M_%S---%p\")\n",
    "    img = Image.fromarray(img)\n",
    "    img = cv2.cvtColor(np.array(img),cv2.COLOR_BGR2RGB) \n",
    "    img_original = cv2.cvtColor(np.array(img_original),cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    faces = masked_model(np.array(img))\n",
    "\n",
    "    for face in faces.xyxy[0]:\n",
    "\n",
    "        save_flag = True\n",
    "        try: confidence = round(face[4].item()*100)\n",
    "        except TypeError: break\n",
    "            \n",
    "        if confidence <60: \n",
    "            save_flag = False \n",
    "        else:\n",
    "            x = round(face[0].item())\n",
    "            y = round(face[1].item())\n",
    "            w = round(face[2].item())\n",
    "            h = round(face[3].item())\n",
    "\n",
    "            if face[5].item() == 1:\n",
    "                labale = 'Without Mask'\n",
    "                color = (255,0,0)\n",
    "            else: \n",
    "                labale = 'With Mask'\n",
    "                color = (0,255,0)\n",
    "\n",
    "            resize_frame = img[y:h, x:w]\n",
    "            resize_frame = cv2.resize(resize_frame,(300, 300))\n",
    "            img_original = cv2.rectangle(np.array(img_original), (x+ROI_Region[0], y+ROI_Region[1]\n",
    "                                                                  ,abs(w-(x)),abs(h-(y))), color, 2)\n",
    "            img_original = cv2.putText(np.array(img_original), f'{labale}', (x+ROI_Region[0], y+ROI_Region[1])\n",
    "                                       , cv2.FONT_HERSHEY_SIMPLEX, 1, color,2,cv2.LINE_AA) \n",
    "\n",
    "        if save_flag: \n",
    "            img_original = cv2.cvtColor(np.array(img_original),cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(f'Test/{now_time}.jpg',img)\n",
    "            img_original = cv2.cvtColor(np.array(img_original),cv2.COLOR_BGR2RGB)\n",
    "        else: pass\n",
    "\n",
    "    img_original = cv2.resize(img_original, (1250, 750))        \n",
    "    img_original = cv2.cvtColor(img_original,cv2.COLOR_RGB2BGR)\n",
    "    return img_original,resize_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse_click(event, x, y, flags, param):\n",
    "    global ROI_Region\n",
    "    global img_original\n",
    "    global img_save\n",
    "    \n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        ROI_Region = cv2.selectROI(\"Select Area\",img_original)\n",
    "        print(ROI_Region)\n",
    "        cv2.destroyAllWindows()\n",
    "    elif event == cv2.EVENT_MBUTTONDOWN:\n",
    "        ROI_Region = [0,0,0,0]\n",
    "    else: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class ThreadedCamera(object):\n",
    "    def __init__(self, source='cam:Sayda@0.0.0.0:88/videoMain'):\n",
    "\n",
    "        self.capture = cv2.VideoCapture(f'rtsp://{source}', cv2.CAP_FFMPEG)\n",
    "\n",
    "        self.thread = Thread(target = self.update, args = ())\n",
    "        self.thread.daemon = True\n",
    "        self.thread.start()\n",
    "\n",
    "        self.status = False\n",
    "        self.frame  = None\n",
    "\n",
    "    def update(self):\n",
    "        while True:\n",
    "            if self.capture.isOpened(): (self.status, self.frame) = self.capture.read()\n",
    "            else: continue\n",
    "\n",
    "    def grab_frame(self):\n",
    "        if self.status: return self.frame\n",
    "        else: return None \n",
    "    \n",
    "    def end_frame(self):\n",
    "        self.capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_Region = [0,0,0,0]\n",
    "\n",
    "\n",
    "frame_list,counter = [],0\n",
    "# streamer_1 = ThreadedCamera('rtsp:Ashkan321@172.16.60.121')\n",
    "streamer_2 = ThreadedCamera('cam:Sayda@0.0.0.0:88/videoMain')#ThreadedCamera('rtsp:Ashkan123@172.16.60.122')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True: \n",
    "    img_original = streamer_2.grab_frame()\n",
    "\n",
    "    \n",
    "    try: img_original = Image.fromarray(img_original)\n",
    "    except AttributeError: continue\n",
    "       \n",
    "    img_original = cv2.resize(np.array(img_original), (frame_x, frame_y))\n",
    "\n",
    " \n",
    "    img2 = img_original.copy()\n",
    "    img_save2 = img_original.copy()\n",
    "    \n",
    "    \n",
    "    \n",
    "    try: \n",
    "        if ROI_Region[0] == ROI_Region[1] and ROI_Region[2] == ROI_Region[3]:\n",
    "            if ROI_Region[0] == 0 and ROI_Region[0] == ROI_Region[3]: pass\n",
    "            else: \n",
    "                img2 = img2[int(ROI_Region[1]):int(ROI_Region[1]+ROI_Region[3]),\n",
    "                            int(ROI_Region[0]):int(ROI_Region[0]+ROI_Region[2])]\n",
    "        else: \n",
    "            img2 = img2[int(ROI_Region[1]):int(ROI_Region[1]+ROI_Region[3]),\n",
    "                        int(ROI_Region[0]):int(ROI_Region[0]+ROI_Region[2])]\n",
    " \n",
    "    except IndexError: pass\n",
    "    \n",
    "    \n",
    "   \n",
    "        \n",
    "    if img_original is None: img_res2 = np.zeros([frame_y,frame_x,3],dtype=np.uint8)\n",
    "    else: img_res2,_ = Masked_Detection(img2,img_original,ROI_Region)\n",
    "        \n",
    "\n",
    "    img_res2 = cv2.resize(img_res2, (frame_x, frame_y))\n",
    "    cv2.imshow('Mask_Detection', np.array(img_res2))\n",
    "    \n",
    "    cv2.setMouseCallback('Mask_Detection', mouse_click)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        cv2.destroyAllWindows()\n",
    "        streamer_2.end_frame()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
